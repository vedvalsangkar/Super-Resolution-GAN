{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_model_pytorch",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MibNXwqNr7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/jbhuang0604/SelfExSR\n",
        "\n",
        "# import torch\n",
        "# import pandas as pd\n",
        "from torch import nn  # , optim\n",
        "\n",
        "\n",
        "# from torch.nn import functional as F\n",
        "# from torch.utils.data.dataset import Dataset\n",
        "# from torchvision import transforms\n",
        "# from PIL import Image\n",
        "#\n",
        "# from sklearn.metrics import roc_curve, auc\n",
        "# from matplotlib import pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M6BMpaONwbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------Unit residual Block ------------------------------------\n",
        "\n",
        "\n",
        "class BasicGenBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, kernel_size=3, stride=1, channels=64, bias=True):\n",
        "        super(BasicGenBlock, self).__init__()\n",
        "\n",
        "        self.k_size = kernel_size\n",
        "        self.padding = self.k_size // 2\n",
        "        self.stride = stride\n",
        "        self.bias = bias\n",
        "\n",
        "        self.channels = channels\n",
        "\n",
        "        self.layers = nn.Sequential(nn.Conv2d(in_channels=self.channels,\n",
        "                                              out_channels=self.channels,\n",
        "                                              kernel_size=self.k_size,\n",
        "                                              stride=self.stride,\n",
        "                                              padding=self.padding,\n",
        "                                              bias=self.bias),\n",
        "                                    nn.BatchNorm2d(self.channels),\n",
        "                                    nn.PReLU(),\n",
        "                                    nn.Conv2d(in_channels=self.channels,\n",
        "                                              out_channels=self.channels,\n",
        "                                              kernel_size=self.k_size,\n",
        "                                              stride=self.stride,\n",
        "                                              padding=self.padding,\n",
        "                                              bias=self.bias),\n",
        "                                    nn.BatchNorm2d(self.channels)\n",
        "                                    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "\n",
        "        return x + out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw2xRwQvNzEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#------------------------------------------generator defination------------------------------------------\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, upscale_factor, init_kernel_size=9, kernel_size=3, stride=1, channels=64, bias=True):\n",
        "        \"\"\"\n",
        "        Model initializer method.\n",
        "\n",
        "        :param bias: Bias in system (default False).\n",
        "        :param kernel_size: Convolution kernel size.\n",
        "        \"\"\"\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_k_size = init_kernel_size\n",
        "        self.init_padding = self.init_k_size // 2\n",
        "\n",
        "        self.k_size = kernel_size\n",
        "        self.padding = self.k_size // 2\n",
        "\n",
        "        self.st = stride\n",
        "        self.bias = bias\n",
        "\n",
        "        self.intrim_channels = channels\n",
        "        self.final_channels = channels * (upscale_factor ** 2)\n",
        "\n",
        "        self.upscale_factor = upscale_factor\n",
        "\n",
        "        # self.upsample_mode = 'nearest'\n",
        "        # r\"\"\"\n",
        "        # Upsampling algorithm: one of ``'nearest'``, ``'linear'``, ``'bilinear'``, ``'bicubic'``x and ``'trilinear'``.\n",
        "        # \"\"\"\n",
        "\n",
        "        self.init_layer = nn.Sequential(nn.Conv2d(in_channels=3,\n",
        "                                                  out_channels=self.intrim_channels,\n",
        "                                                  kernel_size=self.init_k_size,\n",
        "                                                  stride=self.st,\n",
        "                                                  padding=self.init_padding,\n",
        "                                                  bias=self.bias),\n",
        "                                        nn.PReLU()\n",
        "                                        )\n",
        "\n",
        "        self.blocks_layer = nn.Sequential(BasicGenBlock(kernel_size=self.k_size,\n",
        "                                                        stride=self.st,\n",
        "                                                        channels=self.intrim_channels,\n",
        "                                                        bias=self.bias),\n",
        "                                          BasicGenBlock(kernel_size=self.k_size,\n",
        "                                                        stride=self.st,\n",
        "                                                        channels=self.intrim_channels,\n",
        "                                                        bias=self.bias),\n",
        "                                          BasicGenBlock(kernel_size=self.k_size,\n",
        "                                                        stride=self.st,\n",
        "                                                        channels=self.intrim_channels,\n",
        "                                                        bias=self.bias),\n",
        "                                          BasicGenBlock(kernel_size=self.k_size,\n",
        "                                                        stride=self.st,\n",
        "                                                        channels=self.intrim_channels,\n",
        "                                                        bias=self.bias),\n",
        "                                          BasicGenBlock(kernel_size=self.k_size,\n",
        "                                                        stride=self.st,\n",
        "                                                        channels=self.intrim_channels,\n",
        "                                                        bias=self.bias)\n",
        "                                          )\n",
        "\n",
        "        self.intrim_layer = nn.Sequential(nn.Conv2d(in_channels=self.intrim_channels,\n",
        "                                                    out_channels=self.intrim_channels,\n",
        "                                                    kernel_size=self.k_size,\n",
        "                                                    stride=self.st,\n",
        "                                                    padding=self.padding,\n",
        "                                                    bias=self.bias),\n",
        "                                          nn.BatchNorm2d(self.intrim_channels)\n",
        "                                          )\n",
        "\n",
        "        self.pixel_layer = nn.Sequential(nn.Conv2d(in_channels=self.intrim_channels,\n",
        "                                                   out_channels=self.final_channels,\n",
        "                                                   kernel_size=self.k_size,\n",
        "                                                   stride=self.st,\n",
        "                                                   padding=self.padding,\n",
        "                                                   bias=self.bias),\n",
        "                                         nn.PixelShuffle(upscale_factor=self.upscale_factor),\n",
        "                                         nn.PReLU(),\n",
        "                                         nn.Conv2d(in_channels=self.intrim_channels,\n",
        "                                                   out_channels=self.final_channels,\n",
        "                                                   kernel_size=self.k_size,\n",
        "                                                   stride=self.st,\n",
        "                                                   padding=self.padding,\n",
        "                                                   bias=self.bias),\n",
        "                                         nn.PixelShuffle(upscale_factor=self.upscale_factor),\n",
        "                                         nn.PReLU()\n",
        "                                         )\n",
        "        \"\"\"\n",
        "        The input channels for both convolutions is 64 and output is 64 * (Scale_Factor ^ 2).\n",
        "        \"\"\"\n",
        "\n",
        "        self.final_conv = nn.Conv2d(in_channels=self.intrim_channels,\n",
        "                                    out_channels=3,\n",
        "                                    kernel_size=self.init_k_size,\n",
        "                                    stride=self.st,\n",
        "                                    padding=self.init_padding,\n",
        "                                    bias=self.bias)\n",
        "\n",
        "#---------------------------------------Forward prop -- define the computation performed at every cell\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_var = self.init_layer(x)\n",
        "        out = self.blocks_layer(skip_var)\n",
        "        out = self.intrim_layer(out)\n",
        "        out = self.pixel_layer(out + skip_var)\n",
        "        out = self.final_conv(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRao64wlN24R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------------------------------------- Unit block in discriminator ---------------------------------\n",
        "\n",
        "\n",
        "\n",
        "class BasicDisBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, kernel_size=3, stride=1, in_channels=64, out_channels=64, bias=True):\n",
        "        super(BasicDisBlock, self).__init__()\n",
        "\n",
        "        self.k_size = kernel_size\n",
        "        self.padding = self.k_size // 2\n",
        "        self.stride = stride\n",
        "        self.bias = bias\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.layer = nn.Sequential(nn.Conv2d(in_channels=self.in_channels,\n",
        "                                             out_channels=self.out_channels,\n",
        "                                             kernel_size=self.k_size,\n",
        "                                             stride=self.stride,\n",
        "                                             padding=self.padding,\n",
        "                                             bias=self.bias),\n",
        "                                   nn.BatchNorm2d(self.out_channels),\n",
        "                                   nn.LeakyReLU(),\n",
        "                                   )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9bjtDMYN5mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#--------------------------------------------------------Defination of Discriminator -------------------------------------------\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, image_size=(224, 224), bias=False):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.k_size = 3\n",
        "        self.padding = self.k_size // 2\n",
        "        self.bias = bias\n",
        "\n",
        "        # else:\n",
        "        self.input_image_size = image_size\n",
        "        if len(image_size) != 2:\n",
        "            raise ValueError(\"Input Image size must be a tuple (Width x Height)\")\n",
        "\n",
        "        self.flattened_feat = (self.input_image_size[0] // 16) * (self.input_image_size[1] // 16) * 512\n",
        "\n",
        "        self.init_layer = nn.Sequential(nn.Conv2d(in_channels=3,\n",
        "                                                  out_channels=64,\n",
        "                                                  kernel_size=self.k_size,\n",
        "                                                  stride=1,\n",
        "                                                  padding=self.padding,\n",
        "                                                  bias=self.bias),\n",
        "                                        nn.LeakyReLU()\n",
        "                                        )\n",
        "\n",
        "        self.blocks_layer = nn.Sequential(BasicDisBlock(kernel_size=self.k_size,\n",
        "                                                        stride=2,\n",
        "                                                        in_channels=64,\n",
        "                                                        out_channels=64,\n",
        "                                                        bias=self.bias),\n",
        "                                          BasicDisBlock(kernel_size=self.k_size,\n",
        "                                                        stride=1,\n",
        "                                                        in_channels=64,\n",
        "                                                        out_channels=128,\n",
        "                                                        bias=self.bias),\n",
        "                                          BasicDisBlock(kernel_size=self.k_size,\n",
        "                                                        stride=2,\n",
        "                                                        in_channels=128,\n",
        "                                                        out_channels=128,\n",
        "                                                        bias=self.bias),\n",
        "                                          BasicDisBlock(kernel_size=self.k_size,\n",
        "                                                        stride=1,\n",
        "                                                        in_channels=128,\n",
        "                                                        out_channels=256,\n",
        "                                                        bias=self.bias),\n",
        "                                          BasicDisBlock(kernel_size=self.k_size,\n",
        "                                                        stride=2,\n",
        "                                                        in_channels=256,\n",
        "                                                        out_channels=256,\n",
        "                                                        bias=self.bias),\n",
        "                                          BasicDisBlock(kernel_size=self.k_size,\n",
        "                                                        stride=1,\n",
        "                                                        in_channels=256,\n",
        "                                                        out_channels=512,\n",
        "                                                        bias=self.bias),\n",
        "                                          BasicDisBlock(kernel_size=self.k_size,\n",
        "                                                        stride=2,\n",
        "                                                        in_channels=512,\n",
        "                                                        out_channels=512,\n",
        "                                                        bias=self.bias),\n",
        "                                          )\n",
        "\n",
        "        self.linear_layer = nn.Sequential(nn.Linear(in_features=self.flattened_feat,\n",
        "                                                    out_features=1024,\n",
        "                                                    bias=self.bias),\n",
        "                                          nn.LeakyReLU()\n",
        "                                          )\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.Linear(in_features=1024,\n",
        "                                                  out_features=1,\n",
        "                                                  bias=self.bias),\n",
        "                                        nn.Sigmoid()\n",
        "                                        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.init_layer(x)\n",
        "        out = self.blocks_layer(out)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        # print(\"OUT SHAPE:\", out.shape)\n",
        "        out = self.linear_layer(out)\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}